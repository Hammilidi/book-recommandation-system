{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed07559f-8ac0-4cf4-90c3-d86fa2f537fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Inspection du schéma de la base ===\n",
      "Colonnes disponibles dans la table 'livres':\n",
      "     column_name         data_type\n",
      "0          titre              text\n",
      "1    description              text\n",
      "2           prix  double precision\n",
      "3  disponibilite            bigint\n",
      "4      image_url              text\n",
      "5           note            bigint\n",
      "\n",
      "=== Entraînement du système de recommandation ===\n",
      "Données chargées: 998 livres\n",
      "Aperçu des données:\n",
      "   id                                  titre  \\\n",
      "0   0                   A Light in the Attic   \n",
      "1   1                     Tipping the Velvet   \n",
      "2   2                             Soumission   \n",
      "3   3                          Sharp Objects   \n",
      "4   4  Sapiens: A Brief History of Humankind   \n",
      "\n",
      "                                         description  \\\n",
      "0  It's hard to imagine a world without A Light i...   \n",
      "1  \"Erotic and absorbing...Written with starling ...   \n",
      "2  Dans une France assez proche de la nôtre, un h...   \n",
      "3  WICKED above her hipbone, GIRL across her hear...   \n",
      "4  From a renowned historian comes a groundbreaki...   \n",
      "\n",
      "                                           image_url  stock  rating   prix  \n",
      "0  https://books.toscrape.com/media/cache/2c/da/2...      0       3  51.77  \n",
      "1  https://books.toscrape.com/media/cache/26/0c/2...      0       1  53.74  \n",
      "2  https://books.toscrape.com/media/cache/3e/ef/3...      0       1  50.10  \n",
      "3  https://books.toscrape.com/media/cache/32/51/3...      0       4  47.82  \n",
      "4  https://books.toscrape.com/media/cache/be/a5/b...      0       5  54.23  \n",
      "\n",
      "Types de colonnes:\n",
      "id               int64\n",
      "titre           object\n",
      "description     object\n",
      "image_url       object\n",
      "stock            int64\n",
      "rating           int64\n",
      "prix           float64\n",
      "dtype: object\n",
      "Matrice TF-IDF créée: (998, 5000)\n",
      "Matrice de similarité cosinus calculée\n",
      "Modèle sauvegardé dans models/recommendation_model.joblib\n",
      "\n",
      "=== Test recommandations par titre ===\n",
      "Test avec le titre: 'A Light in the Attic'\n",
      "- Quarter Life Poetry: Poems for the Young, Broke and Hangry (Score: 0.171)\n",
      "- Twenty Love Poems and a Song of Despair (Score: 0.159)\n",
      "- salt. (Score: 0.142)\n",
      "\n",
      "=== Test recommandations par description ===\n",
      "- The Course of Love (Score: 0.175)\n",
      "- Charity's Cross (Charles Towne Belles #4) (Score: 0.168)\n",
      "- Reasons to Stay Alive (Score: 0.142)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import joblib\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "from typing import List, Dict\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ==============================\n",
    "# 1. Connexion à la base de données via SQLAlchemy\n",
    "# ==============================\n",
    "def connect_db_engine():\n",
    "    \"\"\"Connexion à la base via SQLAlchemy engine\"\"\"\n",
    "    db_user = os.getenv('DB_USER', 'postgres')\n",
    "    db_pass = os.getenv('DB_PASSWORD', 'admin')\n",
    "    db_host = os.getenv('DB_HOST', 'localhost')\n",
    "    db_port = os.getenv('DB_PORT', '5432')\n",
    "    db_name = os.getenv('DB_NAME', 'booksdb')\n",
    "\n",
    "    db_uri = f\"postgresql+psycopg2://{db_user}:{db_pass}@{db_host}:{db_port}/{db_name}\"\n",
    "    engine = create_engine(db_uri)\n",
    "    return engine\n",
    "\n",
    "# ==============================\n",
    "# 2. Chargement des données\n",
    "# ==============================\n",
    "def load_data_from_db():\n",
    "    \"\"\"Charger les données depuis la base\"\"\"\n",
    "    try:\n",
    "        engine = connect_db_engine()\n",
    "        # Fixed: Using actual column names from schema inspection\n",
    "        query = \"\"\"\n",
    "            SELECT titre, description, image_url, \n",
    "                   disponibilite as stock, note as rating, prix\n",
    "            FROM livres\n",
    "            WHERE description IS NOT NULL AND description != ''\n",
    "        \"\"\"\n",
    "        df = pd.read_sql_query(query, engine)\n",
    "\n",
    "        # Création d'un identifiant interne\n",
    "        df = df.reset_index().rename(columns={\"index\": \"id\"})\n",
    "\n",
    "        print(f\"Données chargées: {len(df)} livres\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur chargement données : {e}\")\n",
    "        return None\n",
    "\n",
    "# ==============================\n",
    "# 3. Alternative: Function to inspect database schema\n",
    "# ==============================\n",
    "def inspect_database_schema():\n",
    "    \"\"\"Inspecter le schéma de la base pour connaître les noms exacts des colonnes\"\"\"\n",
    "    try:\n",
    "        engine = connect_db_engine()\n",
    "        query = \"\"\"\n",
    "            SELECT column_name, data_type \n",
    "            FROM information_schema.columns \n",
    "            WHERE table_name = 'livres'\n",
    "            ORDER BY ordinal_position;\n",
    "        \"\"\"\n",
    "        columns_info = pd.read_sql_query(query, engine)\n",
    "        print(\"Colonnes disponibles dans la table 'livres':\")\n",
    "        print(columns_info)\n",
    "        return columns_info\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur inspection schéma : {e}\")\n",
    "        return None\n",
    "\n",
    "# ==============================\n",
    "# 4. Prétraitement du texte\n",
    "# ==============================\n",
    "def preprocess_text(text):\n",
    "    if not text or pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).lower()  # Added str() conversion for safety\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "# ==============================\n",
    "# 5. Préparation TF-IDF\n",
    "# ==============================\n",
    "def prepare_tfidf_matrix(df):\n",
    "    try:\n",
    "        df['description_clean'] = df['description'].apply(preprocess_text)\n",
    "        df['combined_features'] = df['titre'].fillna('') + ' ' + df['description_clean'].fillna('')\n",
    "        vectorizer = TfidfVectorizer(\n",
    "            max_features=5000,\n",
    "            stop_words='english',\n",
    "            ngram_range=(1, 2),\n",
    "            min_df=2,\n",
    "            max_df=0.8\n",
    "        )\n",
    "        tfidf_matrix = vectorizer.fit_transform(df['combined_features'])\n",
    "        print(f\"Matrice TF-IDF créée: {tfidf_matrix.shape}\")\n",
    "        return vectorizer, tfidf_matrix\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur TF-IDF: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# ==============================\n",
    "# 6. Calcul Similarité Cosinus\n",
    "# ==============================\n",
    "def compute_cosine_similarity_matrix(tfidf_matrix, df):\n",
    "    try:\n",
    "        cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "        book_indices = pd.Series(df.index, index=df['titre']).drop_duplicates()\n",
    "        print(\"Matrice de similarité cosinus calculée\")\n",
    "        return cosine_sim, book_indices\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur similarité: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# ==============================\n",
    "# 7. Recommandations par titre\n",
    "# ==============================\n",
    "def get_recommendations_by_title(title, df, cosine_sim, book_indices, n=5):\n",
    "    try:\n",
    "        if title not in book_indices:\n",
    "            possible_titles = df[df['titre'].str.contains(title, case=False, na=False)]\n",
    "            if possible_titles.empty:\n",
    "                return []\n",
    "            title = possible_titles.iloc[0]['titre']\n",
    "        idx = book_indices[title]\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:n+1]\n",
    "        recommendations = []\n",
    "        for i, score in sim_scores:\n",
    "            book = df.iloc[i]\n",
    "            recommendations.append({\n",
    "                'id': int(book['id']),\n",
    "                'titre': book['titre'],\n",
    "                'description': book['description'][:200] + ('...' if len(str(book['description'])) > 200 else ''),\n",
    "                'image_url': book['image_url'],\n",
    "                'rating': float(book['rating']) if pd.notna(book['rating']) else 0.0,\n",
    "                'stock': int(book['stock']) if pd.notna(book['stock']) else 0,\n",
    "                'prix': float(book['prix']) if pd.notna(book['prix']) else 0.0,\n",
    "                'similarity_score': float(score)\n",
    "            })\n",
    "        return recommendations\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur recommandations par titre : {e}\")\n",
    "        return []\n",
    "\n",
    "# ==============================\n",
    "# 8. Recommandations par description\n",
    "# ==============================\n",
    "def get_recommendations_by_description(user_desc, df, vectorizer, tfidf_matrix, n=5):\n",
    "    try:\n",
    "        processed_desc = preprocess_text(user_desc)\n",
    "        user_tfidf = vectorizer.transform([processed_desc])\n",
    "        similarities = cosine_similarity(user_tfidf, tfidf_matrix).flatten()\n",
    "        similar_indices = similarities.argsort()[::-1][:n]\n",
    "        recommendations = []\n",
    "        for idx in similar_indices:\n",
    "            if similarities[idx] > 0:\n",
    "                book = df.iloc[idx]\n",
    "                recommendations.append({\n",
    "                    'id': int(book['id']),\n",
    "                    'titre': book['titre'],\n",
    "                    'description': book['description'][:200] + ('...' if len(str(book['description'])) > 200 else ''),\n",
    "                    'image_url': book['image_url'],\n",
    "                    'rating': float(book['rating']) if pd.notna(book['rating']) else 0.0,\n",
    "                    'stock': int(book['stock']) if pd.notna(book['stock']) else 0,\n",
    "                    'prix': float(book['prix']) if pd.notna(book['prix']) else 0.0,\n",
    "                    'similarity_score': float(similarities[idx])\n",
    "                })\n",
    "        return recommendations\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur recommandations par description : {e}\")\n",
    "        return []\n",
    "\n",
    "# ==============================\n",
    "# 9. Sauvegarde/Chargement modèle\n",
    "# ==============================\n",
    "def save_model(filepath, vectorizer, tfidf_matrix, cosine_sim, book_indices, df):\n",
    "    try:\n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "        \n",
    "        model_data = {\n",
    "            'tfidf_vectorizer': vectorizer,\n",
    "            'tfidf_matrix': tfidf_matrix,\n",
    "            'cosine_sim': cosine_sim,\n",
    "            'book_indices': book_indices,\n",
    "            'df': df\n",
    "        }\n",
    "        joblib.dump(model_data, filepath)\n",
    "        print(f\"Modèle sauvegardé dans {filepath}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur sauvegarde: {e}\")\n",
    "        return False\n",
    "\n",
    "def load_model(filepath):\n",
    "    try:\n",
    "        model_data = joblib.load(filepath)\n",
    "        print(f\"Modèle chargé depuis {filepath}\")\n",
    "        return (model_data['tfidf_vectorizer'], model_data['tfidf_matrix'],\n",
    "                model_data['cosine_sim'], model_data['book_indices'], model_data['df'])\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur chargement modèle: {e}\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "# ==============================\n",
    "# 10. Programme principal\n",
    "# ==============================\n",
    "def main():\n",
    "    print(\"=== Inspection du schéma de la base ===\")\n",
    "    inspect_database_schema()\n",
    "    \n",
    "    print(\"\\n=== Entraînement du système de recommandation ===\")\n",
    "    df = load_data_from_db()\n",
    "    if df is None:\n",
    "        return\n",
    "    \n",
    "    print(f\"Aperçu des données:\")\n",
    "    print(df.head())\n",
    "    print(f\"\\nTypes de colonnes:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    vectorizer, tfidf_matrix = prepare_tfidf_matrix(df)\n",
    "    if vectorizer is None:\n",
    "        return\n",
    "    cosine_sim, book_indices = compute_cosine_similarity_matrix(tfidf_matrix, df)\n",
    "    if cosine_sim is None:\n",
    "        return\n",
    "    save_model('models/recommendation_model.joblib', vectorizer, tfidf_matrix, cosine_sim, book_indices, df)\n",
    "\n",
    "    print(\"\\n=== Test recommandations par titre ===\")\n",
    "    # Test with the first book title from the dataframe\n",
    "    if len(df) > 0:\n",
    "        test_title = df.iloc[0]['titre']\n",
    "        print(f\"Test avec le titre: '{test_title}'\")\n",
    "        recs = get_recommendations_by_title(test_title, df, cosine_sim, book_indices, 3)\n",
    "        for rec in recs:\n",
    "            print(f\"- {rec['titre']} (Score: {rec['similarity_score']:.3f})\")\n",
    "    else:\n",
    "        print(\"Aucun livre trouvé pour tester\")\n",
    "\n",
    "    print(\"\\n=== Test recommandations par description ===\")\n",
    "    recs = get_recommendations_by_description(\"I want a romantic adventure story\", df, vectorizer, tfidf_matrix, 3)\n",
    "    for rec in recs:\n",
    "        print(f\"- {rec['titre']} (Score: {rec['similarity_score']:.3f})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
