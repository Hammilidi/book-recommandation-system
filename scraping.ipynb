{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320b0dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début du scraping...\n",
      "Scraping page 1/50...\n",
      "Scraping page 2/50...\n",
      "Scraping page 3/50...\n",
      "Scraping page 4/50...\n",
      "Scraping page 5/50...\n",
      "Scraping page 6/50...\n",
      "Scraping page 7/50...\n",
      "Scraping page 8/50...\n",
      "Scraping page 9/50...\n",
      "Scraping page 10/50...\n",
      "Scraping page 11/50...\n",
      "Scraping page 12/50...\n",
      "Scraping page 13/50...\n",
      "Scraping page 14/50...\n",
      "Scraping page 15/50...\n",
      "Scraping page 16/50...\n",
      "Scraping page 17/50...\n",
      "Scraping page 18/50...\n",
      "Scraping page 19/50...\n",
      "Scraping page 20/50...\n",
      "Scraping page 21/50...\n",
      "Scraping page 22/50...\n",
      "Scraping page 23/50...\n",
      "Scraping page 24/50...\n",
      "Scraping page 25/50...\n",
      "Scraping page 26/50...\n",
      "Scraping page 27/50...\n",
      "Scraping page 28/50...\n",
      "Scraping page 29/50...\n",
      "Scraping page 30/50...\n",
      "Scraping page 31/50...\n",
      "Scraping page 32/50...\n",
      "Scraping page 33/50...\n",
      "Scraping page 34/50...\n",
      "Scraping page 35/50...\n",
      "Scraping page 36/50...\n",
      "Scraping page 37/50...\n",
      "Scraping page 38/50...\n",
      "Scraping page 39/50...\n",
      "Scraping page 40/50...\n",
      "Scraping page 41/50...\n",
      "Scraping page 42/50...\n",
      "Scraping page 43/50...\n",
      "Scraping page 44/50...\n",
      "Scraping page 45/50...\n",
      "Scraping page 46/50...\n",
      "Scraping page 47/50...\n",
      "Scraping page 48/50...\n",
      "Scraping page 49/50...\n",
      "Scraping page 50/50...\n",
      "Scraping terminé. 1000 livres récupérés.\n",
      "\n",
      "Aperçu des données avec ID :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>titre</th>\n",
       "      <th>description</th>\n",
       "      <th>prix</th>\n",
       "      <th>disponibilite</th>\n",
       "      <th>image_url</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A Light in the Attic</td>\n",
       "      <td>It's hard to imagine a world without A Light i...</td>\n",
       "      <td>51.77</td>\n",
       "      <td>0</td>\n",
       "      <td>https://books.toscrape.com/media/cache/2c/da/2...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>\"Erotic and absorbing...Written with starling ...</td>\n",
       "      <td>53.74</td>\n",
       "      <td>0</td>\n",
       "      <td>https://books.toscrape.com/media/cache/26/0c/2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Soumission</td>\n",
       "      <td>Dans une France assez proche de la nôtre, un h...</td>\n",
       "      <td>50.10</td>\n",
       "      <td>0</td>\n",
       "      <td>https://books.toscrape.com/media/cache/3e/ef/3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>WICKED above her hipbone, GIRL across her hear...</td>\n",
       "      <td>47.82</td>\n",
       "      <td>0</td>\n",
       "      <td>https://books.toscrape.com/media/cache/32/51/3...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sapiens: A Brief History of Humankind</td>\n",
       "      <td>From a renowned historian comes a groundbreaki...</td>\n",
       "      <td>54.23</td>\n",
       "      <td>0</td>\n",
       "      <td>https://books.toscrape.com/media/cache/be/a5/b...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                  titre  \\\n",
       "0   0                   A Light in the Attic   \n",
       "1   1                     Tipping the Velvet   \n",
       "2   2                             Soumission   \n",
       "3   3                          Sharp Objects   \n",
       "4   4  Sapiens: A Brief History of Humankind   \n",
       "\n",
       "                                         description   prix  disponibilite  \\\n",
       "0  It's hard to imagine a world without A Light i...  51.77              0   \n",
       "1  \"Erotic and absorbing...Written with starling ...  53.74              0   \n",
       "2  Dans une France assez proche de la nôtre, un h...  50.10              0   \n",
       "3  WICKED above her hipbone, GIRL across her hear...  47.82              0   \n",
       "4  From a renowned historian comes a groundbreaki...  54.23              0   \n",
       "\n",
       "                                           image_url  note  \n",
       "0  https://books.toscrape.com/media/cache/2c/da/2...     3  \n",
       "1  https://books.toscrape.com/media/cache/26/0c/2...     1  \n",
       "2  https://books.toscrape.com/media/cache/3e/ef/3...     1  \n",
       "3  https://books.toscrape.com/media/cache/32/51/3...     4  \n",
       "4  https://books.toscrape.com/media/cache/be/a5/b...     5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aperçu des données:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>titre</th>\n",
       "      <th>description</th>\n",
       "      <th>prix</th>\n",
       "      <th>disponibilite</th>\n",
       "      <th>image_url</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A Light in the Attic</td>\n",
       "      <td>It's hard to imagine a world without A Light i...</td>\n",
       "      <td>51.77</td>\n",
       "      <td>0</td>\n",
       "      <td>https://books.toscrape.com/media/cache/2c/da/2...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>\"Erotic and absorbing...Written with starling ...</td>\n",
       "      <td>53.74</td>\n",
       "      <td>0</td>\n",
       "      <td>https://books.toscrape.com/media/cache/26/0c/2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Soumission</td>\n",
       "      <td>Dans une France assez proche de la nôtre, un h...</td>\n",
       "      <td>50.10</td>\n",
       "      <td>0</td>\n",
       "      <td>https://books.toscrape.com/media/cache/3e/ef/3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>WICKED above her hipbone, GIRL across her hear...</td>\n",
       "      <td>47.82</td>\n",
       "      <td>0</td>\n",
       "      <td>https://books.toscrape.com/media/cache/32/51/3...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sapiens: A Brief History of Humankind</td>\n",
       "      <td>From a renowned historian comes a groundbreaki...</td>\n",
       "      <td>54.23</td>\n",
       "      <td>0</td>\n",
       "      <td>https://books.toscrape.com/media/cache/be/a5/b...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                  titre  \\\n",
       "0   0                   A Light in the Attic   \n",
       "1   1                     Tipping the Velvet   \n",
       "2   2                             Soumission   \n",
       "3   3                          Sharp Objects   \n",
       "4   4  Sapiens: A Brief History of Humankind   \n",
       "\n",
       "                                         description   prix  disponibilite  \\\n",
       "0  It's hard to imagine a world without A Light i...  51.77              0   \n",
       "1  \"Erotic and absorbing...Written with starling ...  53.74              0   \n",
       "2  Dans une France assez proche de la nôtre, un h...  50.10              0   \n",
       "3  WICKED above her hipbone, GIRL across her hear...  47.82              0   \n",
       "4  From a renowned historian comes a groundbreaki...  54.23              0   \n",
       "\n",
       "                                           image_url  note  \n",
       "0  https://books.toscrape.com/media/cache/2c/da/2...     3  \n",
       "1  https://books.toscrape.com/media/cache/26/0c/2...     1  \n",
       "2  https://books.toscrape.com/media/cache/3e/ef/3...     1  \n",
       "3  https://books.toscrape.com/media/cache/32/51/3...     4  \n",
       "4  https://books.toscrape.com/media/cache/be/a5/b...     5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nombre de livres: 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Colonnes: ['id', 'titre', 'description', 'prix', 'disponibilite', 'image_url', 'note']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Types: id                 int64\\ntitre             object\\ndescription       object\\nprix             float64\\ndisponibilite      int64\\nimage_url         object\\nnote               int64\\ndtype: object'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Données sauvegardées dans PostgreSQL avec to_sql()\n",
      "✅ Vérification: 1000 livres dans la base\n",
      "✅ Données également sauvegardées dans data/livres.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# -----------------------\n",
    "# Config PostgreSQL\n",
    "# -----------------------\n",
    "DB_URI = \"postgresql+psycopg2://postgres:admin@localhost:5432/booksdb\"\n",
    "\n",
    "base_url = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
    "site_base = \"https://books.toscrape.com/\"\n",
    "livres = []\n",
    "\n",
    "rating_map = {\n",
    "    \"One\": 1,\n",
    "    \"Two\": 2,\n",
    "    \"Three\": 3,\n",
    "    \"Four\": 4,\n",
    "    \"Five\": 5\n",
    "}\n",
    "\n",
    "# ======= SCRAPING =======\n",
    "print(\"Début du scraping...\")\n",
    "for page in range(1, 51):\n",
    "    url = base_url.format(page)\n",
    "    print(f\"Scraping page {page}/50...\")\n",
    "    response = requests.get(url)\n",
    "    response.encoding = \"latin-1\"\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    articles = soup.find_all(\"article\", class_=\"product_pod\")\n",
    "    \n",
    "    for article in articles:\n",
    "        try:\n",
    "            # Titre\n",
    "            titre = article.h3.a[\"title\"]\n",
    "            titre = titre.encode(\"latin-1\", errors=\"ignore\").decode(\"utf-8\", errors=\"ignore\")\n",
    "            \n",
    "            # Prix\n",
    "            prix_str = article.find(\"p\", class_=\"price_color\").text.strip()\n",
    "            prix_str = prix_str.replace(\"Â\", \"\").replace(\"£\", \"\")\n",
    "            prix = float(prix_str)\n",
    "            \n",
    "            # Stock/Disponibilité\n",
    "            stock_text = article.find(\"p\", class_=\"instock availability\").text.strip()\n",
    "            # Extract number from \"In stock (22 available)\"\n",
    "            import re\n",
    "            stock_match = re.search(r'\\((\\d+)', stock_text)\n",
    "            disponibilite = int(stock_match.group(1)) if stock_match else 0\n",
    "            \n",
    "            # Image URL\n",
    "            img_url = article.find(\"img\")[\"src\"]\n",
    "            img_url = urljoin(site_base, img_url)\n",
    "            \n",
    "            # Rating\n",
    "            rating_class = article.find(\"p\", class_=\"star-rating\")[\"class\"][1]\n",
    "            note = rating_map.get(rating_class, 0)\n",
    "            \n",
    "            # --- Récupération de la description ---\n",
    "            detail_href = article.h3.a[\"href\"]\n",
    "            detail_url = urljoin(site_base + \"catalogue/\", detail_href)\n",
    "            detail_resp = requests.get(detail_url)\n",
    "            detail_resp.encoding = \"latin-1\"\n",
    "            detail_soup = BeautifulSoup(detail_resp.text, \"html.parser\")\n",
    "            \n",
    "            desc_tag = detail_soup.find(\"div\", id=\"product_description\")\n",
    "            if desc_tag:\n",
    "                description = desc_tag.find_next_sibling(\"p\").text.strip()\n",
    "                description = description.encode(\"latin-1\", errors=\"ignore\").decode(\"utf-8\", errors=\"ignore\")\n",
    "            else:\n",
    "                description = \"\"\n",
    "            \n",
    "            livres.append({\n",
    "                'titre': titre,\n",
    "                'description': description,\n",
    "                'prix': prix,\n",
    "                'disponibilite': disponibilite,\n",
    "                'image_url': img_url,\n",
    "                'note': note\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du scraping d'un article: {e}\")\n",
    "            continue\n",
    "\n",
    "print(f\"Scraping terminé. {len(livres)} livres récupérés.\")\n",
    "\n",
    "# ======= CHARGEMENT DIRECT EN DB =======\n",
    "try:\n",
    "    # Créer DataFrame directement\n",
    "    df = pd.DataFrame(livres)\n",
    "    \n",
    "\n",
    "    # Ajouter une colonne 'id' à partir de l'index\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'id'}, inplace=True)\n",
    "    \n",
    "\n",
    "    # Vérifier les données\n",
    "    print(\"\\nAperçu des données avec ID :\")\n",
    "    display(df.head())\n",
    "\n",
    "    \n",
    "    # Vérifier les données\n",
    "    print(\"\\nAperçu des données:\")\n",
    "    display(df.head())\n",
    "    print(f\"\\nNombre de livres: {len(df)}\")\n",
    "    display(f\"Colonnes: {list(df.columns)}\")\n",
    "    display(f\"Types: {df.dtypes}\")\n",
    "    \n",
    "    # Connexion PostgreSQL via SQLAlchemy\n",
    "    engine = create_engine(DB_URI)\n",
    "    \n",
    "    # Sauvegarde dans la table \"livres\" \n",
    "    df.to_sql(\"livres\", engine, if_exists=\"replace\", index=False)\n",
    "    \n",
    "    print(\"✅ Données sauvegardées dans PostgreSQL avec to_sql()\")\n",
    "    \n",
    "    # Vérification\n",
    "    verification_query = \"SELECT COUNT(*) as total FROM livres\"\n",
    "    result = pd.read_sql_query(verification_query, engine)\n",
    "    print(f\"✅ Vérification: {result['total'].iloc[0]} livres dans la base\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"❌ Erreur lors de la sauvegarde dans PostgreSQL :\", e)\n",
    "\n",
    "# ======= SAUVEGARDE CSV OPTIONNELLE =======\n",
    "try:\n",
    "    csv_file = \"data/livres.csv\"\n",
    "    df.to_csv(csv_file, index=False, encoding=\"utf-8\")\n",
    "    print(f\"✅ Données également sauvegardées dans {csv_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur sauvegarde CSV: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f61615c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début du scraping...\n",
      "Scraping page 1/50...\n",
      "Scraping page 2/50...\n",
      "Scraping page 3/50...\n",
      "Scraping page 4/50...\n",
      "Scraping page 5/50...\n",
      "Scraping page 6/50...\n",
      "Scraping page 7/50...\n",
      "Scraping page 8/50...\n",
      "Scraping page 9/50...\n",
      "Scraping page 10/50...\n",
      "Scraping page 11/50...\n",
      "Scraping page 12/50...\n",
      "Scraping page 13/50...\n",
      "Scraping page 14/50...\n",
      "Scraping page 15/50...\n",
      "Scraping page 16/50...\n",
      "Scraping page 17/50...\n",
      "Scraping page 18/50...\n",
      "Scraping page 19/50...\n",
      "Scraping page 20/50...\n",
      "Scraping page 21/50...\n",
      "Scraping page 22/50...\n",
      "Scraping page 23/50...\n",
      "Scraping page 24/50...\n",
      "Scraping page 25/50...\n",
      "Scraping page 26/50...\n",
      "Scraping page 27/50...\n",
      "Scraping page 28/50...\n",
      "Scraping page 29/50...\n",
      "Scraping page 30/50...\n",
      "Scraping page 31/50...\n",
      "Scraping page 32/50...\n",
      "Scraping page 33/50...\n",
      "Scraping page 34/50...\n",
      "Scraping page 35/50...\n",
      "Scraping page 36/50...\n",
      "Scraping page 37/50...\n",
      "Scraping page 38/50...\n",
      "Scraping page 39/50...\n",
      "Scraping page 40/50...\n",
      "Scraping page 41/50...\n",
      "Scraping page 42/50...\n",
      "Scraping page 43/50...\n",
      "Scraping page 44/50...\n",
      "Scraping page 45/50...\n",
      "Scraping page 46/50...\n",
      "Scraping page 47/50...\n",
      "Scraping page 48/50...\n",
      "Scraping page 49/50...\n",
      "Scraping page 50/50...\n",
      "Scraping terminé. 1000 livres récupérés.\n",
      "✅ Données insérées dans PostgreSQL avec clé primaire auto-incrémentée et stock réel\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float\n",
    "from sqlalchemy.orm import declarative_base, sessionmaker\n",
    "import re\n",
    "\n",
    "# -----------------------\n",
    "# Config PostgreSQL\n",
    "# -----------------------\n",
    "DB_URI = \"postgresql+psycopg2://postgres:admin@localhost:5432/booksdb\"\n",
    "engine = create_engine(DB_URI)\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "# -----------------------\n",
    "# Modèle Livre\n",
    "# -----------------------\n",
    "class Livre(Base):\n",
    "    __tablename__ = \"livres\"\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    titre = Column(String, nullable=False)\n",
    "    description = Column(String)\n",
    "    prix = Column(Float)\n",
    "    disponibilite = Column(Integer)\n",
    "    image_url = Column(String)\n",
    "    note = Column(Integer)\n",
    "\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "# -----------------------\n",
    "# Scraping\n",
    "# -----------------------\n",
    "base_url = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
    "site_base = \"https://books.toscrape.com/\"\n",
    "rating_map = {\"One\": 1, \"Two\": 2, \"Three\": 3, \"Four\": 4, \"Five\": 5}\n",
    "\n",
    "livres_list = []\n",
    "\n",
    "print(\"Début du scraping...\")\n",
    "for page in range(1, 51):\n",
    "    url = base_url.format(page)\n",
    "    print(f\"Scraping page {page}/50...\")\n",
    "    response = requests.get(url)\n",
    "    response.encoding = \"latin-1\"\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    articles = soup.find_all(\"article\", class_=\"product_pod\")\n",
    "    \n",
    "    for article in articles:\n",
    "        try:\n",
    "            # Titre\n",
    "            titre = article.h3.a[\"title\"].encode(\"latin-1\", errors=\"ignore\").decode(\"utf-8\", errors=\"ignore\")\n",
    "            # Prix\n",
    "            prix_str = article.find(\"p\", class_=\"price_color\").text.strip().replace(\"Â\", \"\").replace(\"£\", \"\")\n",
    "            prix = float(prix_str)\n",
    "            # Image\n",
    "            img_url = urljoin(site_base, article.find(\"img\")[\"src\"])\n",
    "            # Rating\n",
    "            rating_class = article.find(\"p\", class_=\"star-rating\")[\"class\"][1]\n",
    "            note = rating_map.get(rating_class, 0)\n",
    "            \n",
    "            # --- Page détail pour description et disponibilité réelle ---\n",
    "            detail_href = article.h3.a[\"href\"]\n",
    "            detail_url = urljoin(site_base + \"catalogue/\", detail_href)\n",
    "            detail_resp = requests.get(detail_url)\n",
    "            detail_resp.encoding = \"latin-1\"\n",
    "            detail_soup = BeautifulSoup(detail_resp.text, \"html.parser\")\n",
    "            \n",
    "            # Description\n",
    "            desc_tag = detail_soup.find(\"div\", id=\"product_description\")\n",
    "            description = desc_tag.find_next_sibling(\"p\").text.strip() if desc_tag else \"\"\n",
    "            description = description.encode(\"latin-1\", errors=\"ignore\").decode(\"utf-8\", errors=\"ignore\")\n",
    "            \n",
    "            # Disponibilité réelle dans la table produit\n",
    "            availability_text = detail_soup.find(\"th\", string=\"Availability\").find_next_sibling(\"td\").text\n",
    "            disponibilite_match = re.search(r'(\\d+)', availability_text)\n",
    "            disponibilite = int(disponibilite_match.group(1)) if disponibilite_match else 0\n",
    "            \n",
    "            # Ajouter à la liste\n",
    "            livres_list.append(Livre(\n",
    "                titre=titre,\n",
    "                description=description,\n",
    "                prix=prix,\n",
    "                disponibilite=disponibilite,\n",
    "                image_url=img_url,\n",
    "                note=note\n",
    "            ))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du scraping d'un article: {e}\")\n",
    "            continue\n",
    "\n",
    "print(f\"Scraping terminé. {len(livres_list)} livres récupérés.\")\n",
    "\n",
    "# -----------------------\n",
    "# Insertion en DB\n",
    "# -----------------------\n",
    "try:\n",
    "    session.bulk_save_objects(livres_list)\n",
    "    session.commit()\n",
    "    print(\"✅ Données insérées dans PostgreSQL avec clé primaire auto-incrémentée et stock réel\")\n",
    "except Exception as e:\n",
    "    session.rollback()\n",
    "    print(f\"❌ Erreur lors de l'insertion en DB : {e}\")\n",
    "finally:\n",
    "    session.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
